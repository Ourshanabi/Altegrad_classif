{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import codecs\n",
    "from os import path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# With the tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read training data\n",
    "with open(\"train.csv\", 'r') as f:\n",
    "    train_data = f.read().splitlines()\n",
    "\n",
    "train_hosts = list()\n",
    "y_train = list()\n",
    "for row in train_data:\n",
    "    host, label = row.split(\",\")\n",
    "    train_hosts.append(host)\n",
    "    y_train.append(label.lower())\n",
    "\n",
    "# Read test data\n",
    "with open(\"test.csv\", 'r') as f:\n",
    "    test_hosts = f.read().splitlines()\n",
    "\n",
    "# Load the textual content of a set of webpages for each host into the dictionary \"text\". \n",
    "# The encoding parameter is required since the majority of our text is french.\n",
    "text = dict()\n",
    "filenames = os.listdir('text/text')\n",
    "for filename in filenames:\n",
    "    with codecs.open(path.join('text/text/', filename), encoding='latin-1') as f: \n",
    "        text[filename] = f.read().replace(\"\\n\", \"\").lower()\n",
    "\n",
    "train_data = list()\n",
    "for host in train_hosts:\n",
    "    if host in text:\n",
    "        train_data.append(text[host])\n",
    "    else:\n",
    "        train_data.append('')\n",
    "\n",
    "# Create the training matrix. Each row corresponds to a web host and each column to a word present in at least 10 web\n",
    "# hosts and at most 1000 web hosts. The value of each entry in a row is equal to the tf-idf weight of that word in the \n",
    "# corresponding web host       \n",
    "\n",
    "vec = TfidfVectorizer(decode_error='ignore', strip_accents='unicode', encoding='latin-1', min_df=10, max_df=1000)\n",
    "X_train = vec.fit_transform(train_data)\n",
    "\n",
    "# Get textual content of web hosts of the test set\n",
    "test_data = list()\n",
    "for host in test_hosts:\n",
    "    if host in text:\n",
    "        test_data.append(text[host])\n",
    "    else:\n",
    "        test_data.append('')\n",
    "\n",
    "# Create the test matrix following the same approach as in the case of the training matrix\n",
    "X_test = vec.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array(X_test.todense())\n",
    "X_train = np.array(X_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 21384) (2125, 21384)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes = ['business/finance','education/research','entertainment','health/medical','news/press','politics/government/law','sports','tech/science']\n",
    "\n",
    "classes_to_label = {'business/finance' : 0,'education/research':1,'entertainment':2,'health/medical':3,'news/press':4,\n",
    "'politics/government/law':5,'sports':6,'tech/science' : 7}\n",
    "\n",
    "emb = [X_train[i] for i in range(len(X_train))] + [X_train[i] for i in range(len(X_test))]\n",
    "hosts = train_hosts + test_hosts\n",
    "labels = [classes_to_label[label] for label in y_train] + [-1 for i in test_hosts]\n",
    "mask = [0 for i in y_train[:-200]] + [1 for i in range(200)] + [-1 for i in test_hosts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_graph_method = pd.DataFrame({'emb': emb, 'label': labels,'host' :hosts, 'mask' : mask })\n",
    "df_graph_method.to_pickle('emb_tfidf_for_graph_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data and put it in a torch geometric format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformer lstm emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_pickle('emb_lstm_for_graph_method')\n",
    "df_emb.drop_duplicates('host',inplace = True) # delete duplicate\n",
    "df_emb.reset_index(inplace = True)\n",
    "df_emb.drop('index',axis = 1, inplace =True)\n",
    "num_features = len(df_emb['emb'][0])\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_pickle('emb_tfidf_for_graph_method')\n",
    "df_emb.drop_duplicates('host',inplace = True) # delete duplicate\n",
    "df_emb.reset_index(inplace = True)\n",
    "df_emb.drop('index',axis = 1, inplace =True)\n",
    "num_features = len(df_emb['emb'][0])\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put it in a torch geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "      <th>host</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.00012147931, -0.7683938, -0.09987722, 0.002...</td>\n",
       "      <td>0</td>\n",
       "      <td>7587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.026015002, 0.53278214, 0.0006760344, 0.001...</td>\n",
       "      <td>2</td>\n",
       "      <td>16150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0029351865, -0.01593118, -0.002883664, -0....</td>\n",
       "      <td>0</td>\n",
       "      <td>9841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.00035103768, 0.5212322, 0.0019309241, 0.013...</td>\n",
       "      <td>0</td>\n",
       "      <td>6441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0009134803, 0.508965, 0.010666804, 0.098105...</td>\n",
       "      <td>2</td>\n",
       "      <td>8533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>[-0.006148623, 0.7345553, 0.02454278, 0.091676...</td>\n",
       "      <td>-1</td>\n",
       "      <td>23783</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>[0.0001064896, 0.6425214, -0.016132945, 0.0028...</td>\n",
       "      <td>-1</td>\n",
       "      <td>16792</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>[-0.041136276, 0.34874263, 0.0041652224, 0.060...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6584</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>[7.500023e-05, 0.574721, -0.0022576374, 0.0076...</td>\n",
       "      <td>-1</td>\n",
       "      <td>13527</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>[-0.0022784944, -0.14634275, -0.006001415, 0.0...</td>\n",
       "      <td>-1</td>\n",
       "      <td>434</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2554 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    emb  label   host  mask\n",
       "0     [0.00012147931, -0.7683938, -0.09987722, 0.002...      0   7587     0\n",
       "1     [-0.026015002, 0.53278214, 0.0006760344, 0.001...      2  16150     0\n",
       "2     [-0.0029351865, -0.01593118, -0.002883664, -0....      0   9841     0\n",
       "3     [0.00035103768, 0.5212322, 0.0019309241, 0.013...      0   6441     0\n",
       "4     [0.0009134803, 0.508965, 0.010666804, 0.098105...      2   8533     0\n",
       "...                                                 ...    ...    ...   ...\n",
       "2549  [-0.006148623, 0.7345553, 0.02454278, 0.091676...     -1  23783    -1\n",
       "2550  [0.0001064896, 0.6425214, -0.016132945, 0.0028...     -1  16792    -1\n",
       "2551  [-0.041136276, 0.34874263, 0.0041652224, 0.060...     -1   6584    -1\n",
       "2552  [7.500023e-05, 0.574721, -0.0022576374, 0.0076...     -1  13527    -1\n",
       "2553  [-0.0022784944, -0.14634275, -0.006001415, 0.0...     -1    434    -1\n",
       "\n",
       "[2554 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.vstack(df_emb['emb']), dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist = [str(host) for host in df_emb['host']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(list(df_emb['label']),dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_weighted_edgelist('edgelist.txt', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, dtype=None, weight='weight', format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = from_scipy_sparse_matrix(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rzhang\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "edge_index, edge_attribute = edge_index[0], torch.tensor(edge_index[1],dtype = torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Data(x=x, edge_index=edge_index,y = labels, edge_attr = edge_attribute)\n",
    "\n",
    "train_idx = [index for index in range(len(df_emb)) if df_emb['mask'][index] == 0]\n",
    "dataset.train_idx = torch.tensor(train_idx, dtype= torch.long)\n",
    "\n",
    "test_mask = [df_emb['mask'][index] == 1 for index in range(len(df_emb)) ]\n",
    "dataset.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "test_idx = [index for index in range(len(df_emb)) if df_emb['mask'][index] == 1]\n",
    "dataset.test_idx = torch.tensor(test_idx, dtype= torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1812])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2.,   2.,   2.,  ...,   2.,   1., 908.], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 16)\n",
    "        self.conv3 = GCNConv(16, 8)\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attribute= data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index)#, edge_attribute)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.,training=self.training)\n",
    "        x = self.conv2(x, edge_index)#, edge_attribute)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x,p=0., training=self.training)\n",
    "        x = self.conv3(x, edge_index)#,edge_attribute)\n",
    "        \n",
    "\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0936, device='cuda:0')\n",
      "tensor(2.0992, device='cuda:0')\n",
      "tensor(1.6020, device='cuda:0')\n",
      "tensor(1.7427, device='cuda:0')\n",
      "tensor(1.6064, device='cuda:0')\n",
      "tensor(1.7366, device='cuda:0')\n",
      "tensor(1.5973, device='cuda:0')\n",
      "tensor(1.7446, device='cuda:0')\n",
      "tensor(1.5961, device='cuda:0')\n",
      "tensor(1.7463, device='cuda:0')\n",
      "tensor(1.5960, device='cuda:0')\n",
      "tensor(1.7456, device='cuda:0')\n",
      "tensor(1.5959, device='cuda:0')\n",
      "tensor(1.7445, device='cuda:0')\n",
      "tensor(1.5957, device='cuda:0')\n",
      "tensor(1.7448, device='cuda:0')\n",
      "tensor(1.5956, device='cuda:0')\n",
      "tensor(1.7450, device='cuda:0')\n",
      "tensor(1.6012, device='cuda:0')\n",
      "tensor(1.7409, device='cuda:0')\n",
      "tensor(1.5951, device='cuda:0')\n",
      "tensor(1.7427, device='cuda:0')\n",
      "tensor(1.5951, device='cuda:0')\n",
      "tensor(1.7436, device='cuda:0')\n",
      "tensor(1.5933, device='cuda:0')\n",
      "tensor(1.7433, device='cuda:0')\n",
      "tensor(1.5922, device='cuda:0')\n",
      "tensor(1.7463, device='cuda:0')\n",
      "tensor(1.5919, device='cuda:0')\n",
      "tensor(1.7463, device='cuda:0')\n",
      "tensor(1.5921, device='cuda:0')\n",
      "tensor(1.7474, device='cuda:0')\n",
      "tensor(1.5919, device='cuda:0')\n",
      "tensor(1.7478, device='cuda:0')\n",
      "tensor(1.5934, device='cuda:0')\n",
      "tensor(1.7429, device='cuda:0')\n",
      "tensor(1.5917, device='cuda:0')\n",
      "tensor(1.7485, device='cuda:0')\n",
      "tensor(1.5918, device='cuda:0')\n",
      "tensor(1.7484, device='cuda:0')\n",
      "tensor(1.5917, device='cuda:0')\n",
      "tensor(1.7482, device='cuda:0')\n",
      "tensor(1.5917, device='cuda:0')\n",
      "tensor(1.7488, device='cuda:0')\n",
      "tensor(1.5916, device='cuda:0')\n",
      "tensor(1.7488, device='cuda:0')\n",
      "tensor(1.5951, device='cuda:0')\n",
      "tensor(1.7471, device='cuda:0')\n",
      "tensor(1.5916, device='cuda:0')\n",
      "tensor(1.7489, device='cuda:0')\n",
      "tensor(1.5913, device='cuda:0')\n",
      "tensor(1.7433, device='cuda:0')\n",
      "tensor(1.5912, device='cuda:0')\n",
      "tensor(1.7438, device='cuda:0')\n",
      "tensor(1.5911, device='cuda:0')\n",
      "tensor(1.7444, device='cuda:0')\n",
      "tensor(1.5911, device='cuda:0')\n",
      "tensor(1.7443, device='cuda:0')\n",
      "tensor(1.5920, device='cuda:0')\n",
      "tensor(1.7418, device='cuda:0')\n",
      "tensor(1.5916, device='cuda:0')\n",
      "tensor(1.7407, device='cuda:0')\n",
      "tensor(1.5907, device='cuda:0')\n",
      "tensor(1.7441, device='cuda:0')\n",
      "tensor(1.5893, device='cuda:0')\n",
      "tensor(1.7457, device='cuda:0')\n",
      "tensor(1.5893, device='cuda:0')\n",
      "tensor(1.7480, device='cuda:0')\n",
      "tensor(1.5895, device='cuda:0')\n",
      "tensor(1.7483, device='cuda:0')\n",
      "tensor(1.5895, device='cuda:0')\n",
      "tensor(1.7479, device='cuda:0')\n",
      "tensor(1.5893, device='cuda:0')\n",
      "tensor(1.7482, device='cuda:0')\n",
      "tensor(1.5889, device='cuda:0')\n",
      "tensor(1.7511, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7515, device='cuda:0')\n",
      "tensor(1.5890, device='cuda:0')\n",
      "tensor(1.7515, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7508, device='cuda:0')\n",
      "tensor(1.6390, device='cuda:0')\n",
      "tensor(1.7355, device='cuda:0')\n",
      "tensor(1.5888, device='cuda:0')\n",
      "tensor(1.7509, device='cuda:0')\n",
      "tensor(1.5888, device='cuda:0')\n",
      "tensor(1.7507, device='cuda:0')\n",
      "tensor(1.5892, device='cuda:0')\n",
      "tensor(1.7511, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7510, device='cuda:0')\n",
      "tensor(1.5888, device='cuda:0')\n",
      "tensor(1.7513, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7514, device='cuda:0')\n",
      "tensor(1.5887, device='cuda:0')\n",
      "tensor(1.7509, device='cuda:0')\n",
      "tensor(1.5887, device='cuda:0')\n",
      "tensor(1.7521, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7521, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7525, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7497, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7498, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7495, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7496, device='cuda:0')\n",
      "tensor(1.5890, device='cuda:0')\n",
      "tensor(1.7472, device='cuda:0')\n",
      "tensor(1.5911, device='cuda:0')\n",
      "tensor(1.7485, device='cuda:0')\n",
      "tensor(1.5891, device='cuda:0')\n",
      "tensor(1.7478, device='cuda:0')\n",
      "tensor(1.6130, device='cuda:0')\n",
      "tensor(1.7596, device='cuda:0')\n",
      "tensor(1.5894, device='cuda:0')\n",
      "tensor(1.7479, device='cuda:0')\n",
      "tensor(1.5891, device='cuda:0')\n",
      "tensor(1.7479, device='cuda:0')\n",
      "tensor(1.5891, device='cuda:0')\n",
      "tensor(1.7476, device='cuda:0')\n",
      "tensor(1.5890, device='cuda:0')\n",
      "tensor(1.7486, device='cuda:0')\n",
      "tensor(1.5887, device='cuda:0')\n",
      "tensor(1.7474, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7473, device='cuda:0')\n",
      "tensor(1.5898, device='cuda:0')\n",
      "tensor(1.7523, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7467, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7475, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7476, device='cuda:0')\n",
      "tensor(1.5888, device='cuda:0')\n",
      "tensor(1.7479, device='cuda:0')\n",
      "tensor(1.5887, device='cuda:0')\n",
      "tensor(1.7473, device='cuda:0')\n",
      "tensor(1.5889, device='cuda:0')\n",
      "tensor(1.7468, device='cuda:0')\n",
      "tensor(1.5887, device='cuda:0')\n",
      "tensor(1.7472, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7482, device='cuda:0')\n",
      "tensor(1.5891, device='cuda:0')\n",
      "tensor(1.7489, device='cuda:0')\n",
      "tensor(1.5886, device='cuda:0')\n",
      "tensor(1.7478, device='cuda:0')\n",
      "tensor(1.5885, device='cuda:0')\n",
      "tensor(1.7469, device='cuda:0')\n",
      "tensor(1.5902, device='cuda:0')\n",
      "tensor(1.7482, device='cuda:0')\n",
      "tensor(1.5880, device='cuda:0')\n",
      "tensor(1.7484, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7480, device='cuda:0')\n",
      "tensor(1.5881, device='cuda:0')\n",
      "tensor(1.7470, device='cuda:0')\n",
      "tensor(1.5920, device='cuda:0')\n",
      "tensor(1.7522, device='cuda:0')\n",
      "tensor(1.5880, device='cuda:0')\n",
      "tensor(1.7478, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7475, device='cuda:0')\n",
      "tensor(1.5883, device='cuda:0')\n",
      "tensor(1.7475, device='cuda:0')\n",
      "tensor(1.5880, device='cuda:0')\n",
      "tensor(1.7464, device='cuda:0')\n",
      "tensor(1.5880, device='cuda:0')\n",
      "tensor(1.7487, device='cuda:0')\n",
      "tensor(1.5880, device='cuda:0')\n",
      "tensor(1.7467, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7468, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7473, device='cuda:0')\n",
      "tensor(1.5878, device='cuda:0')\n",
      "tensor(1.7480, device='cuda:0')\n",
      "tensor(1.5878, device='cuda:0')\n",
      "tensor(1.7477, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7468, device='cuda:0')\n",
      "tensor(1.5879, device='cuda:0')\n",
      "tensor(1.7482, device='cuda:0')\n",
      "tensor(1.5875, device='cuda:0')\n",
      "tensor(1.7481, device='cuda:0')\n",
      "tensor(1.5875, device='cuda:0')\n",
      "tensor(1.7443, device='cuda:0')\n",
      "tensor(1.5869, device='cuda:0')\n",
      "tensor(1.7485, device='cuda:0')\n",
      "tensor(1.5867, device='cuda:0')\n",
      "tensor(1.7478, device='cuda:0')\n",
      "tensor(1.5870, device='cuda:0')\n",
      "tensor(1.7491, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.cross_entropy(out[data.train_idx], data.y[data.train_idx])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%1000 == 0:\n",
    "        print(loss.data)\n",
    "        val_loss = F.cross_entropy(out[data.test_idx], data.y[data.test_idx])\n",
    "        print(val_loss.data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0,  ..., 2, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y[dataset.train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5220\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
