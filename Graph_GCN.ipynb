{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "from torch_geometric.utils import *\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import codecs\n",
    "from os import path\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# With the tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read training data\n",
    "with open(\"train.csv\", 'r') as f:\n",
    "    train_data = f.read().splitlines()\n",
    "\n",
    "train_hosts = list()\n",
    "y_train = list()\n",
    "for row in train_data:\n",
    "    host, label = row.split(\",\")\n",
    "    train_hosts.append(host)\n",
    "    y_train.append(label.lower())\n",
    "\n",
    "# Read test data\n",
    "with open(\"test.csv\", 'r') as f:\n",
    "    test_hosts = f.read().splitlines()\n",
    "\n",
    "# Load the textual content of a set of webpages for each host into the dictionary \"text\". \n",
    "# The encoding parameter is required since the majority of our text is french.\n",
    "text = dict()\n",
    "filenames = os.listdir('text/text')\n",
    "for filename in filenames:\n",
    "    with codecs.open(path.join('text/text/', filename), encoding='latin-1') as f: \n",
    "        text[filename] = f.read().replace(\"\\n\", \"\").lower()\n",
    "\n",
    "train_data = list()\n",
    "for host in train_hosts:\n",
    "    if host in text:\n",
    "        train_data.append(text[host])\n",
    "    else:\n",
    "        train_data.append('')\n",
    "\n",
    "# Create the training matrix. Each row corresponds to a web host and each column to a word present in at least 10 web\n",
    "# hosts and at most 1000 web hosts. The value of each entry in a row is equal to the tf-idf weight of that word in the \n",
    "# corresponding web host       \n",
    "\n",
    "vec = TfidfVectorizer(decode_error='ignore', strip_accents='unicode', encoding='latin-1', min_df=10, max_df=1000)\n",
    "X_train = vec.fit_transform(train_data)\n",
    "\n",
    "# Get textual content of web hosts of the test set\n",
    "test_data = list()\n",
    "for host in test_hosts:\n",
    "    if host in text:\n",
    "        test_data.append(text[host])\n",
    "    else:\n",
    "        test_data.append('')\n",
    "\n",
    "# Create the test matrix following the same approach as in the case of the training matrix\n",
    "X_test = vec.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test = np.array(X_test.todense())\n",
    "X_train = np.array(X_train.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 21384) (2125, 21384)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes = ['business/finance','education/research','entertainment','health/medical','news/press','politics/government/law','sports','tech/science']\n",
    "\n",
    "classes_to_label = {'business/finance' : 0,'education/research':1,'entertainment':2,'health/medical':3,'news/press':4,\n",
    "'politics/government/law':5,'sports':6,'tech/science' : 7}\n",
    "\n",
    "emb = [X_train[i] for i in range(len(X_train))] + [X_train[i] for i in range(len(X_test))]\n",
    "hosts = train_hosts + test_hosts\n",
    "labels = [classes_to_label[label] for label in y_train] + [-1 for i in test_hosts]\n",
    "mask = [0 for i in y_train[:-200]] + [1 for i in range(200)] + [-1 for i in test_hosts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_graph_method = pd.DataFrame({'emb': emb, 'label': labels,'host' :hosts, 'mask' : mask })\n",
    "df_graph_method.to_pickle('emb_tfidf_for_graph_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## transformer lstm emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_pickle('emb_for_graph_method')\n",
    "df_emb.drop_duplicates('host',inplace = True) # delete duplicate\n",
    "df_emb.reset_index(inplace = True)\n",
    "df_emb.drop('index',axis = 1, inplace =True)\n",
    "num_features = len(df_emb['emb'][0])\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## tfidf emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21384\n"
     ]
    }
   ],
   "source": [
    "df_emb = pd.read_pickle('emb_tfidf_for_graph_method')\n",
    "df_emb.drop_duplicates('host',inplace = True) # delete duplicate\n",
    "df_emb.reset_index(inplace = True)\n",
    "df_emb.drop('index',axis = 1, inplace =True)\n",
    "num_features = len(df_emb['emb'][0])\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# put it in a torch geometric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb</th>\n",
       "      <th>label</th>\n",
       "      <th>host</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35315683...</td>\n",
       "      <td>2</td>\n",
       "      <td>16150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>9841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>6441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.0, 0.0, 2.2048557, 0.0, 0.0, 0.0, 0.13...</td>\n",
       "      <td>2</td>\n",
       "      <td>8533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>23783</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>16792</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2551</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.03981618, 0.0, 0.0, 0.0, 0.7...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6584</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>13527</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2553</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>434</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2554 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    emb  label   host  mask\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   7587     0\n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35315683...      2  16150     0\n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   9841     0\n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0   6441     0\n",
       "4     [0.0, 0.0, 0.0, 2.2048557, 0.0, 0.0, 0.0, 0.13...      2   8533     0\n",
       "...                                                 ...    ...    ...   ...\n",
       "2549  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     -1  23783    -1\n",
       "2550  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     -1  16792    -1\n",
       "2551  [0.0, 0.0, 0.0, 0.03981618, 0.0, 0.0, 0.0, 0.7...     -1   6584    -1\n",
       "2552  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     -1  13527    -1\n",
       "2553  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     -1    434    -1\n",
       "\n",
       "[2554 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(np.vstack(df_emb['emb']), dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nodelist = [str(host) for host in df_emb['host']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = torch.tensor(list(df_emb['label']),dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "G = nx.read_weighted_edgelist('edgelist.txt', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_index = nx.to_scipy_sparse_matrix(G, nodelist=nodelist, dtype=None, weight='weight', format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_index = from_scipy_sparse_matrix(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_index, edge_attribute = edge_index[0], edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "edge_index, edge_attribute = add_self_loops(edge_index, edge_weight=edge_attribute, fill_value=1, num_nodes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rzhang\\Anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "edge_attribute = torch.tensor(edge_attribute, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11747])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attribute.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 11747])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Data(x=x, edge_index=edge_index,y = labels, edge_attr = edge_attribute)\n",
    "\n",
    "train_idx = [index for index in range(len(df_emb)) if df_emb['mask'][index] == 0]\n",
    "dataset.train_idx = torch.tensor(train_idx, dtype= torch.long)\n",
    "\n",
    "train_mask = [df_emb['mask'][index] == 0 for index in range(len(df_emb)) ]\n",
    "dataset.train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "\n",
    "test_mask = [df_emb['mask'][index] == 1 for index in range(len(df_emb)) ]\n",
    "dataset.test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "\n",
    "test_idx = [index for index in range(len(df_emb)) if df_emb['mask'][index] == 1]\n",
    "dataset.test_idx = torch.tensor(test_idx, dtype= torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1812])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.edge_attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, 8)\n",
    "        #self.conv3 = GCNConv(16, 8)\n",
    "        \n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attribute = data.x, data.edge_index, data.edge_attr\n",
    "\n",
    "        x = self.conv1(x, edge_index, edge_weight = edge_attribute)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.,training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight = edge_attribute)\n",
    "        \n",
    "\n",
    "\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0213, device='cuda:0')\n",
      "tensor(2.0318, device='cuda:0')\n",
      "tensor(1.5424, device='cuda:0')\n",
      "tensor(1.7457, device='cuda:0')\n",
      "tensor(1.5219, device='cuda:0')\n",
      "tensor(1.7321, device='cuda:0')\n",
      "tensor(1.5129, device='cuda:0')\n",
      "tensor(1.7342, device='cuda:0')\n",
      "tensor(1.5075, device='cuda:0')\n",
      "tensor(1.7296, device='cuda:0')\n",
      "tensor(1.5035, device='cuda:0')\n",
      "tensor(1.7341, device='cuda:0')\n",
      "tensor(1.5005, device='cuda:0')\n",
      "tensor(1.7332, device='cuda:0')\n",
      "tensor(1.4979, device='cuda:0')\n",
      "tensor(1.7381, device='cuda:0')\n",
      "tensor(1.4958, device='cuda:0')\n",
      "tensor(1.7380, device='cuda:0')\n",
      "tensor(1.4948, device='cuda:0')\n",
      "tensor(1.7400, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%1000 == 0:\n",
    "        print(\"train loss\")\n",
    "        print(loss.data)\n",
    "        val_loss = F.cross_entropy(out[data.test_mask], data.y[data.test_mask])\n",
    "        print(\"val loss\")\n",
    "        print(val_loss.data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 0,  ..., 2, 1, 0], device='cuda:0')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.y[dataset.train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5275\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
